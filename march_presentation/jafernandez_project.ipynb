{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p align=\"center\"> AGRON 935 - Semester project</p>\n",
    "\n",
    "**Name:** Javier Fernandez <br/>\n",
    "**Semester:** Spring 2019 <br/>\n",
    "**Project area:** Agronomy <br/>\n",
    "\n",
    "## Table of contents\n",
    "1. [Motivation for the project](#motivation_project)\n",
    "2. [Current state and roadblocks](#state_roadblocks)\n",
    "3. [Future steps](#future_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"motivation_project\"></a>\n",
    "### 1. Motivation for the project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective is to create a code that can determine and calculate the HTT (Hourly Thermal Time) and DTT (Daily Thermal Time) using Kansas Mesonet database for grain filling samples. Periods of time for HTT and DTT calculations will be between a flowering date (starting point) and a sampling date for each data point.\n",
    "\n",
    "Moreover, the code will allow the user to choose a minimum and maximum cardinal temperatures for calculations on HTT and DTT. This will be useful to evaluate and compare different base temperatures for grain filling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\"><img src=\"project_sketch.jpg\" alt=\"sketch_image\" width=\"600\"/></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"state_roadblocks\"></a>\n",
    "### 2. Current state and Roadblocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code now is calculating DTT for each sample in the data. Still the code is needing the input weather data as a .csv file directly from Kansas Mesonet website, and then is organizing the data to obtain each sample DTT.\n",
    "\n",
    "##### Steps:\n",
    "1. [Import modules](#import_modules)\n",
    "2. [Import data](#import_data)\n",
    "3. [Handling missing values](#missing_values)\n",
    "4. [Calculate thermal time for each day](#daily_TT)\n",
    "5. [Sumation of thermal time for each sample](#sample_TT)\n",
    "\n",
    "Input files neccesary are:\n",
    "\n",
    "  - daily and hourly weather .csv file directly from Kansas Mesonet website\n",
    "  \n",
    "  - grain filling or biomass data, especially having columns for sampling date (here \"/Samp..Date2\") and starting counting date (here /Silking2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"import_modules\"></a>\n",
    "***2.1 Import modules***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Working directory for the project files\n",
    "dirname = 'C:/Users/jafernandez.USERS/Desktop/Coding/sandbox/project/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"import_data\"></a>\n",
    "***2.2 Import data***\n",
    "\n",
    "Grain filling data, with sample and flowering dates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(dirname + '2017_GF.csv') # N, H, WC, Strip, and Time are values representing treatments and experimental design\n",
    "df = pd.DataFrame(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Daily weather data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(dirname + \"Daily_2017.csv\", \"r\") \n",
    "wtrD = pd.read_csv(file, sep = \",\")  # We use this method of importing datatframes as I was encountering issues beacuse of multiple headers\n",
    "file.close() \n",
    "\n",
    "#Renaming and dropping unused columns\n",
    "wtrD = wtrD.rename(columns={'Timestamp': 'Day', 'AirTemperature': 'Max', 'AirTemperature.1': 'Min'})\n",
    "wtrD = wtrD.drop([0,1], axis=0) # remove two first rows\n",
    "wtrD = wtrD.iloc[:,[0,2,3]] # keep only selected columns\n",
    "\n",
    "# Converting values to type = float. Errors = coerce return invalid conversions to Nan\n",
    "wtrD['Min'] = pd.to_numeric(wtrD['Min'], errors='coerce')\n",
    "wtrD['Max'] = pd.to_numeric(wtrD['Max'], errors='coerce')\n",
    "\n",
    "# Calculating daily mean temperatures\n",
    "wtrD['Average'] = ((wtrD['Min']) + (wtrD['Max']))/2\n",
    "\n",
    "#wtrD.loc[wtrD['Average'] < 10, 'C'] = 0\n",
    "#wtrD.loc[wtrD['Average'] > 10, 'C'] = wtrD['Average']\n",
    "\n",
    "wtrD.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hourly weather data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the hourly data, Mesonet does not allow to obtain more than 30 days in one same file. In this case we are working with a range of \n",
    "# 3 months, so we will have a total of 3 files\n",
    "\n",
    "wtrH = pd.DataFrame(columns = ['Day', 'Temp']) # Creating an empty dataframe\n",
    "\n",
    "# For loop to open three months at the same time and appending them at the end\n",
    "for i in ['jul', 'aug', 'sept']:\n",
    "    if i == 'jul':\n",
    "        file = \"july_hourly.csv\"\n",
    "    elif i == 'aug':\n",
    "        file = \"aug_hourly.csv\"\n",
    "    elif i == 'sept':\n",
    "        file = \"sept_hourly.csv\"\n",
    "        \n",
    "    daf = open(dirname + file, \"r\") \n",
    "    dat = pd.read_csv(daf, sep = \",\")\n",
    "    daf.close() \n",
    "\n",
    "    dat = dat.rename(columns={'Timestamp': 'Day', 'AirTemperature': 'Temp'})\n",
    "    dat = dat.drop([0,1], axis=0)\n",
    "    dat = dat.iloc[:,[0,2]]\n",
    "    \n",
    "    wtrH = wtrH.append(dat)\n",
    "\n",
    "# Converting values to type = float. Errors = coerce return invalid conversions to Nan\n",
    "wtrH['Temp'] = pd.to_numeric(wtrH['Temp'], errors='coerce') \n",
    "\n",
    "\n",
    "# As the day column contains the day and the hour, we need to separate in two columns these values\n",
    "# For this we split that column based on the space between strings\n",
    "new = wtrH[\"Day\"].str.split(\" \", expand = True) \n",
    " \n",
    "wtrH.drop(columns =[\"Day\"])  # Drop the old \"Day\" column\n",
    "\n",
    "wtrH[\"Day\"]= new[0]\n",
    "wtrH[\"Time\"]= new[1]\n",
    "\n",
    "wtrH.head().append(wtrH.tail())  # Print the first five and last five rows to check that the data is OK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"missing_values\"></a>\n",
    "***2.3 Handling missing values***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's check missing values in our dataframes\n",
    "#print(df.isna().sum())\n",
    "#print(wtrH.isna().sum())\n",
    "#print(wtrD.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This was the most difficult part to define, and I still have not decide if this is the best way to do it. For now, I was able to solve it by:*\n",
    "\n",
    "- For the grain filling database, if missing values are encountered (in this example, is 1 row) we will just drop that row or measurement\n",
    "\n",
    "- For the weather database, missing temperatures will be estimated with the previous recorded value. In this case, we do not have missing values in the daily weather file, so we will focus on the hourly weather data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[pd.notnull(df['DW_mg'])] # Drop rows that are not null in the DW_mg column\n",
    "\n",
    "wtrH = wtrH.fillna(method='ffill')  # ffill stands for forward fill, so it is using the last notNan value to fill a Nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"daily_TT\"></a>\n",
    "***2.4 Calculate thermal time for each day***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use McMaster and Wilhelm (1997) method for calculating DTT, which has been widely used in studies. It assumes a linear relationship using the mean daily temperature, with an upper critical value.\n",
    "\n",
    "- Tmax is the maximum temperature, Tmin is the minimum temperature, Tavg = (Tmax + Tmin)/2 \n",
    "- Tbase is the base temperature = 8 C\n",
    "- Tupp is the upper threshold temperature = 40 C\n",
    "\n",
    "Input = Tmin and Tmax (daily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define a function to calculate each GD for a given temperature.\n",
    "def GDD1 (T_avg, tbase=8, Tupp = 40):\n",
    "    if T_avg <= tbase:\n",
    "        GD = 0\n",
    "    elif T_avg >= Tupp:\n",
    "        GD = Tupp - tbase\n",
    "    else:\n",
    "        GD = T_avg - tbase\n",
    "    \n",
    "    return GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We apply the function to each row in the daily weather file and we store it into a new column named GDD1.\n",
    "wtrD['GDD1'] = wtrD.Average.apply(GDD1)\n",
    "wtrD.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"sample_TT\"></a>\n",
    "***2.5 Sumation of thermal time for each sample***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the dates as a same format for all the values we will be using\n",
    "df['Sampling'] = pd.to_datetime(df['Sampling'], format='%m/%d/%Y')\n",
    "df['Flowering'] = pd.to_datetime(df['Flowering'], format='%m/%d/%Y')\n",
    "wtrD['Day'] = pd.to_datetime(wtrD['Day'], format='%Y/%m/%d')\n",
    "wtrH['Day'] = pd.to_datetime(wtrH['Day'], format='%Y/%m/%d')\n",
    "\n",
    "# In this section we calculated the sum of GDD or thermal time based on the new calculated weather file.\n",
    "# For this, we define a function that actually performs the sumation indexing on sampling and flowering dates\n",
    "\n",
    "def calc (start, end):\n",
    "      \n",
    "    TT = wtrD[(wtrD.Day >= start) & (wtrD.Day <= end)].GDD1.sum()\n",
    "    return TT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we need to iterate this function across all my rows in the dataframe, so I found the intertuples function useful.\n",
    "\n",
    "mylist = [] # create an empty list\n",
    "for row in df.itertuples():\n",
    "    TT = calc(row.Flowering, row.Sampling)\n",
    "    mylist.append(TT)   #append the TT values for each row in a list\n",
    "\n",
    "# Add that list as a new column named GDD1 in our dataframe\n",
    "\n",
    "df['GDD1'] = np.asarray(mylist)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"future_steps\"></a>\n",
    "### 3. Future Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The following step will be to create a function that caluclates HTT using the hourly datafile, and then calculate the sumation correspondent to each sample date. Basically, it will do the same as DTT but using hourly data.\n",
    "\n",
    "- The next part of the code should be able to retrieve the specific .csv file from Mesonet website, just entering the dates and weather station."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
